Traceback (most recent call last):
  File "/nfs/hpc/share/soloww/WOFOSTGym/train_agent.py", line 68, in <module>
    ag_trainer(args)
  File "/nfs/hpc/share/soloww/WOFOSTGym/rl_algs/RPPO.py", line 213, in train
    writer.add_scalar("charts/average_reward", eval_policy_lstm(agent, envs, kwargs, device), global_step)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/nfs/hpc/share/soloww/WOFOSTGym/rl_algs/rl_utils.py", line 225, in eval_policy_lstm
    action, next_lstm_state = policy.get_action(state, next_lstm_state, torch.tensor(np.logical_or(term, trunc)).to(device))
                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/nfs/hpc/share/soloww/WOFOSTGym/rl_algs/RPPO.py", line 119, in get_action
    hidden, lstm_state = self.get_states(x, lstm_state, done)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/nfs/hpc/share/soloww/WOFOSTGym/rl_algs/RPPO.py", line 103, in get_states
    hidden = hidden.reshape((-1, batch_size, self.lstm.input_size))
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: shape '[-1, 4, 512]' is invalid for input of size 512
